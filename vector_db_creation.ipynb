{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/divyasingh2611/RAG-Fast-Api/blob/main/faissdb_finance_report.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vF9yYvtWKef9"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain langchain_community pdfplumber faiss-cpu torch accelerate pytesseract huggingface_hub -qq -U\n",
        "!pip install bitsandbytes transformers xformers -qq -U"
      ],
      "metadata": {
        "collapsed": true,
        "id": "-wbzyaOXLXKN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt install tesseract-ocr\n",
        "!sudo apt install libtesseract-dev"
      ],
      "metadata": {
        "id": "V0BjjIIQWgaI",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wE_kkmMXNXeK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Storing Api's key"
      ],
      "metadata": {
        "id": "C7aGmmuqrRV1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "key_1=userdata.get('huggingface')\n",
        "key_2=userdata.get('gemini')"
      ],
      "metadata": {
        "id": "xmp7kzalSJ-h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Extracting Text and Table's from pdfs"
      ],
      "metadata": {
        "id": "Eiw87q1Grk3d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pdfplumber\n",
        "import pytesseract\n",
        "from PIL import Image\n",
        "import csv\n",
        "from io import StringIO\n",
        "\n",
        "\n",
        "# Path to your folder containing PDFs\n",
        "pdf_folder = \"/content/drive/MyDrive/work/data\"\n",
        "# output_folder= \"/content/drive/MyDrive/work/output_folder\"\n",
        "\n",
        "# Ensure output folder exists\n",
        "os.makedirs(\"output_folder\", exist_ok=True)\n",
        "\n",
        "def clamp_bbox(bbox, page_width, page_height):\n",
        "    \"\"\"Ensure the bounding box is within the page boundaries.\"\"\"\n",
        "    x0, top, x1, bottom = bbox\n",
        "    return max(0, min(x0, page_width)), max(0, min(top, page_height)), \\\n",
        "           max(0, min(x1, page_width)), max(0, min(bottom, page_height))\n",
        "\n",
        "def extract_text_and_tables_from_pdf(pdf_path):\n",
        "    \"\"\"Extract text, OCR text from images, and tables from a single PDF and store everything in a variable.\"\"\"\n",
        "    output_text = \"\"\n",
        "\n",
        "    with pdfplumber.open(pdf_path) as pdf:\n",
        "        for i, page in enumerate(pdf.pages):\n",
        "            output_text += f\"--- Page {i + 1} ---\\n\"\n",
        "\n",
        "            # Extract text from the page\n",
        "            text = page.extract_text()\n",
        "            if text:\n",
        "                output_text += \"Extracted Text:\\n\"\n",
        "                output_text += text + \"\\n\"\n",
        "\n",
        "            # Extract tables and format them as a string\n",
        "            tables = page.extract_tables()\n",
        "            for table_index, table in enumerate(tables):\n",
        "                output_text += f\"Table {table_index + 1} on Page {i + 1}:\\n\"\n",
        "                for row in table:\n",
        "                    # Handle None values in the table cells\n",
        "                    output_text += \", \".join(str(cell) if cell is not None else \"\" for cell in row) + \"\\n\"\n",
        "\n",
        "            # Extract images and perform OCR on them\n",
        "            for image_index, image in enumerate(page.images):\n",
        "                x0, top, x1, bottom = image[\"x0\"], image[\"top\"], image[\"x1\"], image[\"bottom\"]\n",
        "                page_width, page_height = page.width, page.height\n",
        "\n",
        "                # Clamp the bounding box to stay within the page boundaries\n",
        "                clamped_bbox = clamp_bbox((x0, top, x1, bottom), page_width, page_height)\n",
        "\n",
        "                # Crop the image using the clamped bounding box\n",
        "                img = page.crop(clamped_bbox)\n",
        "                pil_image = img.to_image().original\n",
        "\n",
        "                # Ensure the image has valid dimensions\n",
        "                if pil_image.width > 0 and pil_image.height > 0:\n",
        "                    # Perform OCR on the image\n",
        "                    ocr_text = pytesseract.image_to_string(pil_image)\n",
        "                    if ocr_text.strip():\n",
        "                        output_text += f\"OCR Text from Image {image_index + 1} on Page {i + 1}:\\n\"\n",
        "                        output_text += ocr_text + \"\\n\"\n",
        "                else:\n",
        "                    output_text += f\"Warning: Invalid image size in Page {i + 1}, Image {image_index + 1}\\n\"\n",
        "\n",
        "            output_text += \"\\n\"\n",
        "\n",
        "    return output_text\n",
        "\n",
        "# Process all PDFs in the folder and accumulate the extracted content in a variable\n",
        "all_pdf_text = \"\"\n",
        "for file in os.listdir(pdf_folder):\n",
        "    if file.endswith(\".pdf\"):\n",
        "        pdf_path = os.path.join(pdf_folder, file)\n",
        "        pdf_text = extract_text_and_tables_from_pdf(pdf_path)\n",
        "        all_pdf_text += pdf_text\n",
        "\n",
        "# Output the combined result as a single string\n",
        "print(all_pdf_text)"
      ],
      "metadata": {
        "id": "8gEe2gETjEpQ",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chunking"
      ],
      "metadata": {
        "id": "cQBsjkpIzP4r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.docstore.document import Document"
      ],
      "metadata": {
        "id": "Nb9c5auyOAVq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=4096, chunk_overlap=409)\n",
        "chunks = text_splitter.split_text(all_pdf_text)\n",
        "\n",
        "# Convert chunks (strings) to Document objects\n",
        "docs = [Document(page_content=chunk) for chunk in chunks]\n"
      ],
      "metadata": {
        "id": "tv8CMpKNzPk0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Embeddings"
      ],
      "metadata": {
        "id": "Ckjcu96PvFHE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.vectorstores import FAISS\n",
        "import os"
      ],
      "metadata": {
        "id": "iL4Vy9S6OQOq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a vectorstore folder to store the FAISS vector database embeddings\n",
        "vectorstore_path ='/content/drive/MyDrive/work'\n",
        "db_faiss_path = os.path.join(vectorstore_path, 'db_faiss')\n",
        "\n",
        "# Create the directories\n",
        "os.makedirs(db_faiss_path, exist_ok=True)\n",
        "# Verify directory creation\n",
        "os.path.exists(vectorstore_path), os.path.exists(db_faiss_path)"
      ],
      "metadata": {
        "id": "He-JE5keQSfu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import notebook_login\n",
        "notebook_login()"
      ],
      "metadata": {
        "id": "KUU4N4UYkjbl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings = HuggingFaceEmbeddings(model_name='FinLang/finance-embeddings-investopedia',model_kwargs={'device':'cuda'})\n",
        "\n",
        "db = FAISS.from_documents(docs, embeddings)\n",
        "db.save_local(db_faiss_path)\n",
        "print(\"Saved into the vector database\")"
      ],
      "metadata": {
        "id": "b8RGdQioOTFO",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ypB0yFDCSQ3s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2mAN5vu_xM5a"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
